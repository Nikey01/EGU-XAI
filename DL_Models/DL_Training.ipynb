{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import lime\n",
    "import lime.lime_image\n",
    "from keras.models import load_model\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import cv2\n",
    "\n",
    "# Load all models\n",
    "models = {\n",
    "    \"Deeper CNN\": load_model(\"cnn_deeper.h5\"),\n",
    "    \"RNN\": load_model(\"rnn.h5\"),\n",
    "    \"LSTM\": load_model(\"lstm.h5\"),\n",
    "    \"Capsule Network\": load_model(\"capsule.h5\"),\n",
    "}\n",
    "\n",
    "# Load test image\n",
    "def load_test_image(path=\"test_digit.png\"):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (28, 28))\n",
    "    img = img.astype(\"float32\") / 255.0\n",
    "    return img\n",
    "\n",
    "# Preprocess for model input\n",
    "def preprocess_for_model(img):\n",
    "    return np.expand_dims(np.expand_dims(img, axis=-1), axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n",
    "    grad_model = tf.keras.models.Model(\n",
    "        [model.inputs], \n",
    "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
    "    )\n",
    "\n",
    "    grad_model.summary()\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        conv_outputs, predictions = grad_model(img_array)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        output = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(output, conv_outputs)\n",
    "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
    "    conv_outputs = conv_outputs[0]\n",
    "    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]\n",
    "    heatmap = tf.squeeze(heatmap)\n",
    "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
    "    return heatmap.numpy()\n",
    "\n",
    "def display_gradcam(img, heatmap, alpha=0.4):\n",
    "    heatmap = cv2.resize(heatmap, (28, 28))\n",
    "    heatmap = np.uint8(255 * heatmap)\n",
    "    heatmap_colored = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
    "    img_color = cv2.cvtColor(np.uint8(img * 255), cv2.COLOR_GRAY2BGR)\n",
    "    overlay = cv2.addWeighted(img_color, 1 - alpha, heatmap_colored, alpha, 0)\n",
    "    plt.imshow(overlay)\n",
    "    plt.title(\"Grad-CAM Overlay\")\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_with_lime(image, model):\n",
    "    explainer = lime.lime_image.LimeImageExplainer()\n",
    "    def predict_fn(imgs):\n",
    "        imgs = np.array([\n",
    "            cv2.cvtColor(cv2.resize(i, (28, 28)), cv2.COLOR_RGB2GRAY)\n",
    "            for i in imgs\n",
    "        ])\n",
    "        imgs = imgs[..., np.newaxis] / 255.0\n",
    "        return model.predict(imgs)\n",
    "\n",
    "    explanation = explainer.explain_instance(\n",
    "        image=cv2.cvtColor((image * 255).astype(\"uint8\"), cv2.COLOR_GRAY2RGB),\n",
    "        classifier_fn=predict_fn,\n",
    "        top_labels=1,\n",
    "        hide_color=0,\n",
    "        num_samples=500\n",
    "    )\n",
    "    temp, mask = explanation.get_image_and_mask(\n",
    "        explanation.top_labels[0],\n",
    "        positive_only=True,\n",
    "        num_features=5,\n",
    "        hide_rest=False\n",
    "    )\n",
    "    plt.imshow(mark_boundaries(temp / 255.0, mask))\n",
    "    plt.title(\"LIME Explanation\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_with_shap(model, image):\n",
    "    background = np.stack([image for _ in range(100)])\n",
    "    explainer = shap.GradientExplainer(model, background)\n",
    "    shap_values = explainer.shap_values(np.expand_dims(image, axis=0))\n",
    "    shap.image_plot(shap_values, np.expand_dims(image, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Integrated Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrated_gradients(model, input_image, baseline=None, steps=50):\n",
    "    input_image = tf.convert_to_tensor(input_image[0], dtype=tf.float32)\n",
    "\n",
    "    if baseline is None:\n",
    "        baseline = tf.zeros_like(input_image)\n",
    "    else:\n",
    "        baseline = tf.convert_to_tensor(baseline[0], dtype=tf.float32)\n",
    "\n",
    "    interpolated = tf.stack([\n",
    "        baseline + (float(i) / steps) * (input_image - baseline)\n",
    "        for i in range(steps + 1)\n",
    "    ])\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(interpolated)\n",
    "        predictions = model(interpolated)\n",
    "        pred_index = tf.argmax(predictions[-1])\n",
    "        outputs = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(outputs, interpolated)\n",
    "    avg_grads = tf.reduce_mean(grads, axis=0)\n",
    "\n",
    "    integrated_grads = (input_image - baseline) * avg_grads\n",
    "    return integrated_grads.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saliency Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_map(model, input_image):\n",
    "    input_image = tf.convert_to_tensor(input_image, dtype=tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(input_image)\n",
    "        predictions = model(input_image)\n",
    "        pred_index = tf.argmax(predictions[0])\n",
    "        output = predictions[:, pred_index]\n",
    "\n",
    "    grads = tape.gradient(output, input_image)\n",
    "    saliency = tf.abs(grads)\n",
    "    return saliency.numpy()[0, ..., 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image\n",
    "img_raw = load_test_image()\n",
    "img_input = preprocess_for_model(img_raw)\n",
    "\n",
    "# Define the last conv layer name per CNN model\n",
    "last_conv_layers = {\n",
    "    \"Deeper CNN\": \"conv2d_2\",      # <- check via model.summary() if different\n",
    "    \"Capsule Network\": \"conv2d_7\",   # <- also confirm via model.summary()\n",
    "}\n",
    "\n",
    "# Loop through models and apply XAI\n",
    "for model_name, model in models.items():\n",
    "    print(f\"\\nðŸ” Explaining predictions for: {model_name}\")\n",
    "    \n",
    "    # LIME\n",
    "    try:\n",
    "        print(\"âž¡ LIME\")\n",
    "        explain_with_lime((img_raw * 255).astype(\"uint8\"), model)\n",
    "    except Exception as e:\n",
    "        print(\"LIME failed:\", e)\n",
    "\n",
    "    # Grad-CAM (only for CNNs)\n",
    "    if model_name in last_conv_layers:\n",
    "        try:\n",
    "            print(\"âž¡ Grad-CAM\")\n",
    "            heatmap = make_gradcam_heatmap(img_input, model, last_conv_layers[model_name])\n",
    "            display_gradcam(img_raw, heatmap)\n",
    "        except Exception as e:\n",
    "            print(\"Grad-CAM failed:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_explanation_map(img, explanation, title):\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.imshow(explanation, cmap='inferno', alpha=0.6)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed input (1, 28, 28, 1)\n",
    "input_img = preprocess_for_model(img_raw)\n",
    "\n",
    "# For Deeper CNN\n",
    "ig = integrated_gradients(models[\"Deeper CNN\"], input_img)\n",
    "sal = saliency_map(models[\"Deeper CNN\"], input_img)\n",
    "\n",
    "display_explanation_map(img_raw, np.squeeze(ig), \"Integrated Gradients\")\n",
    "display_explanation_map(img_raw, sal, \"Saliency Map\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
